<!DOCTYPE html>
<html lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="naver-site-verification" content="046c0adddf4769b5ef392d86e11c8d31a979c621"/>

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <!-- Twitter Cards -->
	<meta name="twitter:title" content="텍스트마이닝: Word Representation">
	<meta name="twitter:description" content="텍스트(데이터) 수집 방법

python을 사용하여 데이터를 크롤링하는 방법을 배운다. 본격적으로 코드에 대해 언급하기 전에 알아야 할 인코딩이나 환경에 대하여 먼저 서술한다.

">
	
	
	
	<meta name="twitter:card" content="summary">
	<meta name="twitter:image" content="https://user-images.githubusercontent.com/33674947/56813408-d1b1d400-6877-11e9-9b4f-893fcc6254c6.jpg">
	

	<!-- Open Graph -->
	<meta property="og:locale" content="">
	<meta property="og:type" content="article">
	<meta property="og:title" content="텍스트마이닝: Word Representation">
	
	<meta name="og:image" content="https://user-images.githubusercontent.com/33674947/56813408-d1b1d400-6877-11e9-9b4f-893fcc6254c6.jpg">
	

	<meta property="og:description" content="텍스트(데이터) 수집 방법

python을 사용하여 데이터를 크롤링하는 방법을 배운다. 본격적으로 코드에 대해 언급하기 전에 알아야 할 인코딩이나 환경에 대하여 먼저 서술한다.

">
	<meta property="og:url" content="jgtonys.github.io/bigdata/2019/05/16/textmining-word-representation/">
	<meta property="og:site_name" content="Jungyu Kim">


  <title>
    
      텍스트마이닝: Word Representation &middot; Jungyu Kim
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/main.css">
  <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Serif:400,400italic,700%7CPT+Sans:400">

  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/public/apple-touch-icon-precomposed.png">
  <link rel="shortcut icon" href="/public/favicon.ico">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">

  <script src="https://code.jquery.com/jquery-3.4.0.min.js" integrity="sha256-BJeo0qm959uMBGb65z40ejJYGSgR7REI4+CW1fNKwOg=" crossorigin="anonymous"></script>

  
  <script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_SVG"> </script>
  <script type="text/x-mathjax-config">
MathJax.Hub.Config({ tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ], processEscapes: true } });
  </script>
  
</head>


  <body>

    <!-- Target for toggling the sidebar `.sidebar-checkbox` is for regular
     styles, `#sidebar-checkbox` for behavior. -->
<input type="checkbox" class="sidebar-checkbox" id="sidebar-checkbox">

<!-- Toggleable sidebar -->
<div class="sidebar" id="sidebar">
  <div class="sidebar-item">
    <div class="sidebar-personal-info">
      <div class="sidebar-personal-info-section">
        <a href="https://github.com/jgtonys">
          <p><strong>Jungyu Kim</strong>
          <i class="fa fa-github" aria-hidden="true"></i></p>
        </a>
        </a>
      </div>
      <div class="sidebar-personal-info-section">
        <p>Wanted to be a <strong>developer</strong><br>And I <strong>am a developer</strong></p>
      </div>
      
      
      
      <div class="sidebar-personal-info-section">
        <p> Contact: 
        
        
        
        <a href="https://github.com/jgtonys">
          <i class="fa fa-github" aria-hidden="true"></i>
        </a>
        
        |
        
        
        
        <a href="https://facebook.com/jgtony">
          <i class="fa fa-facebook" aria-hidden="true"></i>
        </a>
        
        |
        
        
        
        <a href="http://www.google.com/recaptcha/mailhide/d?k=01I3lZFiZYng9N3QxYEtsDaQ==&c=31wAnZkuKqcG0ATAqJN8Z3ln5kkYLA9TwkGc-IbygpM=">
          <i class="fa fa-envelope" aria-hidden="true"></i>
        </a>
        
        |
        
        
        
        <a href="http://www.linkedin.com/in/준규-김-devj">
          <i class="fa fa-linkedin" aria-hidden="true"></i>
        </a>
        
        
        
        </p>
      </div>
      
    </div>
  </div>

  <nav class="sidebar-nav">
    
      
      
      

      

      <span class="">
        <a class="sidebar-nav-item " href="/">
          Home
        </a>

        
      </span>

    
      
      
      

      

      <span class="foldable">
        <a class="sidebar-nav-item " href="/blog/">
          Blog
        </a>

        
          
            
            
            
              <a class="sidebar-nav-item sidebar-nav-item-sub " href="/blog/categories/">
                Categories
              </a>
          
        
          
            
            
            
              <a class="sidebar-nav-item sidebar-nav-item-sub " href="/blog/tags/">
                Tags
              </a>
          
        
      </span>

    
      
      
      

      

      <span class="">
        <a class="sidebar-nav-item " href="/about/">
          About
        </a>

        
      </span>

    
      
      
      

      

      <span class="">
        <a class="sidebar-nav-item " href="http://github.com/jgtonys/">
          Github Project
        </a>

        
      </span>

    

    <!--<span class="sidebar-nav-item">Currently v1.0.0</span>-->
  </nav>

  <div class="sidebar-item">
    <p>
    &copy; 2019 Jungyu Kim.
    </p>
  </div>

  <div class="sidebar-item">
    <p>
    Powered by <a href="http://jekyllrb.com">jekyll</a>
    </p>
  </div>
</div>


    <!-- Wrap is the content to shift when toggling the sidebar. We wrap the
         content to avoid any CSS collisions with our real content. -->
    <div class="wrap">
      <div class="masthead">
        <div class="container">
          <h3 class="masthead-title">
            <a href="/" title="Home" title="Jungyu Kim">
              <!--<img class="masthead-logo" src="/public/logo.jpg"/>-->
              <strong>Jgtony</strong>
            </a>
            <small>Developer blog</small>
          </h3>
        </div>
      </div>

      <div class="container content">
        <div class="post">
  <span class="post-date">16 May 2019</span>
  <h1 class="post-title">텍스트마이닝: Word Representation</h1>
  
  <div class="post-div">
    
    <a href="/blog/tags/#textmining" class="post-tag">textmining</a>
    
    <a href="/blog/tags/#python" class="post-tag">python</a>
    
    <a href="/blog/tags/#html" class="post-tag">html</a>
    
  </div>
  
  <article>
    <script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>
    <h2 id="텍스트데이터-수집-방법"><strong>텍스트(데이터) 수집 방법</strong></h2>

<p>python을 사용하여 데이터를 크롤링하는 방법을 배운다. 본격적으로 코드에 대해 언급하기 전에 알아야 할 인코딩이나 환경에 대하여 먼저 서술한다.</p>

<!-- more -->

<hr />

<h2 id="different-types-of-word-embeddings"><strong>Different types of Word Embeddings</strong></h2>

<ul>
  <li>빈도수 기반 Embedding : Count Vector, TF-IDF Vector, Co-Occurrence Vector</li>
  <li>예측 기반 Embedding : CBOW(Continuous Bag of words), Skip-Gram model</li>
</ul>

<p><br /></p>

<p><strong>Distributional Embeddings</strong></p>

<p><strong>Training Methods</strong></p>

<p>tdm의 특징 sparse 하다 (필요없는 정보 예를들어 0이 많음)</p>

<p><br /></p>

<p><strong>GloVe</strong></p>

<p>Word Representation 을 위한 Global Vector 이다.</p>

<p><strong>FastText</strong></p>

<p>페이스북에서 제작한 word2bag 의 변형. 단어단위가 아니라 캐릭터 단위의 레벨을 사용하며 스킵-그램 모델의 확장이다. n-gram 단위로 학습한다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="kn">import</span> <span class="nn">re</span>  <span class="c1"># For preprocessing
</span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>  <span class="c1"># For data handling
</span><span class="kn">from</span> <span class="nn">time</span> <span class="kn">import</span> <span class="n">time</span>  <span class="c1"># To time our operations
</span><span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">defaultdict</span>  <span class="c1"># For word frequency
</span>
<span class="kn">import</span> <span class="nn">spacy</span>  <span class="c1"># For preprocessing
</span>
<span class="c1"># python -m spacy download en_core_web_sm
</span>
<span class="kn">import</span> <span class="nn">logging</span>  <span class="c1"># Setting up the loggings to monitor gensim
</span><span class="n">logging</span><span class="o">.</span><span class="n">basicConfig</span><span class="p">(</span><span class="nb">format</span><span class="o">=</span><span class="s">"</span><span class="si">%(levelname)</span><span class="s">s - </span><span class="si">%(asctime)</span><span class="s">s: </span><span class="si">%(message)</span><span class="s">s"</span><span class="p">,</span> <span class="n">datefmt</span><span class="o">=</span> <span class="s">'</span><span class="si">%</span><span class="s">H:</span><span class="si">%</span><span class="s">M:</span><span class="si">%</span><span class="s">S'</span><span class="p">,</span> <span class="n">level</span><span class="o">=</span><span class="n">logging</span><span class="o">.</span><span class="n">INFO</span><span class="p">)</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'data/simpsons_dataset.csv'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>

<span class="k">def</span> <span class="nf">cleaning</span><span class="p">(</span><span class="n">doc</span><span class="p">):</span>
    <span class="c1"># Lemmatizes and removes stopwords
</span>    <span class="c1"># doc needs to be a spacy Doc object
</span>    <span class="n">txt</span> <span class="o">=</span> <span class="p">[</span><span class="n">token</span><span class="o">.</span><span class="n">lemma_</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">doc</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">token</span><span class="o">.</span><span class="n">is_stop</span><span class="p">]</span>
    <span class="c1"># Word2Vec uses context words to learn the vector representation of a target word,
</span>    <span class="c1"># if a sentence is only one or two words long,
</span>    <span class="c1"># the benefit for the training is very small
</span>    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">txt</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">:</span>
        <span class="k">return</span> <span class="s">' '</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">txt</span><span class="p">)</span>

<span class="n">brief_cleaning</span> <span class="o">=</span> <span class="p">(</span><span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s">"[^A-Za-z']+"</span><span class="p">,</span> <span class="s">' '</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">row</span><span class="p">))</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">df</span><span class="p">[</span><span class="s">'spoken_words'</span><span class="p">])</span>

<span class="n">t</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>
<span class="n">nlp</span> <span class="o">=</span> <span class="n">spacy</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s">'en_core_web_sm'</span><span class="p">,</span> <span class="n">disable</span><span class="o">=</span><span class="p">[</span><span class="s">'ner'</span><span class="p">,</span> <span class="s">'parser'</span><span class="p">])</span> <span class="c1"># disabling Named Entity Recognition for speed
</span><span class="n">txt</span> <span class="o">=</span> <span class="p">[</span><span class="n">cleaning</span><span class="p">(</span><span class="n">doc</span><span class="p">)</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">nlp</span><span class="o">.</span><span class="n">pipe</span><span class="p">(</span><span class="n">brief_cleaning</span><span class="p">)]</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Time to clean up everything: {} mins'</span><span class="o">.</span><span class="nb">format</span><span class="p">(</span><span class="nb">round</span><span class="p">((</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">t</span><span class="p">)</span> <span class="o">/</span> <span class="mi">60</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>

<span class="n">df_clean</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s">'clean'</span><span class="p">:</span> <span class="n">txt</span><span class="p">})</span>
<span class="n">df_clean</span> <span class="o">=</span> <span class="n">df_clean</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span><span class="o">.</span><span class="n">drop_duplicates</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="n">df_clean</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>



<span class="kn">from</span> <span class="nn">gensim.models.phrases</span> <span class="kn">import</span> <span class="n">Phrases</span><span class="p">,</span> <span class="n">Phraser</span>

<span class="n">sent</span> <span class="o">=</span> <span class="p">[</span><span class="n">row</span><span class="o">.</span><span class="n">split</span><span class="p">()</span> <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">df_clean</span><span class="p">[</span><span class="s">'clean'</span><span class="p">]]</span>
<span class="n">phrases</span> <span class="o">=</span> <span class="n">Phrases</span><span class="p">(</span><span class="n">sent</span><span class="p">,</span> <span class="n">min_count</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">progress_per</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span>
<span class="n">bigram</span> <span class="o">=</span> <span class="n">Phraser</span><span class="p">(</span><span class="n">phrases</span><span class="p">)</span>
<span class="n">sentences</span> <span class="o">=</span> <span class="n">bigram</span><span class="p">[</span><span class="n">sent</span><span class="p">]</span>

<span class="c1"># Most Frequent Words:
</span><span class="n">word_freq</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">sentences</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">sentence</span><span class="p">:</span>
        <span class="n">word_freq</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
<span class="nb">len</span><span class="p">(</span><span class="n">word_freq</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="n">word_freq</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="n">word_freq</span><span class="o">.</span><span class="n">get</span><span class="p">,</span> <span class="n">reverse</span><span class="o">=</span><span class="bp">True</span><span class="p">)[:</span><span class="mi">10</span><span class="p">])</span>

<span class="c1"># Train the Model
</span><span class="kn">import</span> <span class="nn">multiprocessing</span>
<span class="kn">from</span> <span class="nn">gensim.models</span> <span class="kn">import</span> <span class="n">Word2Vec</span>

<span class="n">cores</span> <span class="o">=</span> <span class="n">multiprocessing</span><span class="o">.</span><span class="n">cpu_count</span><span class="p">()</span> <span class="c1"># Count the number of cores in a computer
</span><span class="n">w2v_model</span> <span class="o">=</span> <span class="n">Word2Vec</span><span class="p">(</span><span class="n">min_count</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">window</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span> <span class="n">sample</span><span class="o">=</span><span class="mf">6e-5</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.03</span><span class="p">,</span>
                     <span class="n">min_alpha</span><span class="o">=</span><span class="mf">0.0007</span><span class="p">,</span> <span class="n">negative</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span><span class="n">workers</span><span class="o">=</span><span class="n">cores</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># min_count = int - Ignores all words with total absolute frequency lower than this - (2, 100)
# window = int - The maximum distance between the current and predicted word within a sentence. E.g. window words on the left and window words on the left of our target - (2, 10)
# size = int - Dimensionality of the feature vectors. - (50, 300)
# sample = float - The threshold for configuring which higher-frequency words are randomly downsampled. Highly influencial. - (0, 1e-5)
# alpha = float - The initial learning rate - (0.01, 0.05)
# min_alpha = float - Learning rate will linearly drop to min_alpha as training progresses. To set it: alpha - (min_alpha * epochs) ~ 0.00
# negative = int - If &gt; 0, negative sampling will be used, the int for negative specifies how many "noise words" should be drown. If set to 0, no negative sampling is used. - (5, 20)
# workers = int - Use these many worker threads to train the model (=faster training with multicore machines)
</span>
<span class="n">t</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>
<span class="n">w2v_model</span><span class="o">.</span><span class="n">build_vocab</span><span class="p">(</span><span class="n">sentences</span><span class="p">,</span> <span class="n">progress_per</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Time to build vocab: {} mins'</span><span class="o">.</span><span class="nb">format</span><span class="p">(</span><span class="nb">round</span><span class="p">((</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">t</span><span class="p">)</span> <span class="o">/</span> <span class="mi">60</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>

<span class="n">t</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>
<span class="n">w2v_model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">sentences</span><span class="p">,</span> <span class="n">total_examples</span><span class="o">=</span><span class="n">w2v_model</span><span class="o">.</span><span class="n">corpus_count</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">report_delay</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Time to train the model: {} mins'</span><span class="o">.</span><span class="nb">format</span><span class="p">(</span><span class="nb">round</span><span class="p">((</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">t</span><span class="p">)</span> <span class="o">/</span> <span class="mi">60</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>

<span class="n">w2v_model</span><span class="o">.</span><span class="n">init_sims</span><span class="p">(</span><span class="n">replace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">w2v_model</span><span class="o">.</span><span class="n">wv</span><span class="o">.</span><span class="n">most_similar</span><span class="p">(</span><span class="n">positive</span><span class="o">=</span><span class="p">[</span><span class="s">"homer"</span><span class="p">]))</span>
<span class="k">print</span><span class="p">(</span><span class="n">w2v_model</span><span class="o">.</span><span class="n">wv</span><span class="o">.</span><span class="n">most_similar</span><span class="p">(</span><span class="n">positive</span><span class="o">=</span><span class="p">[</span><span class="s">"homer_simpson"</span><span class="p">]))</span>
<span class="k">print</span><span class="p">(</span><span class="n">w2v_model</span><span class="o">.</span><span class="n">wv</span><span class="o">.</span><span class="n">most_similar</span><span class="p">(</span><span class="n">positive</span><span class="o">=</span><span class="p">[</span><span class="s">"marge"</span><span class="p">]))</span>

<span class="k">print</span><span class="p">(</span><span class="n">w2v_model</span><span class="o">.</span><span class="n">wv</span><span class="o">.</span><span class="n">similarity</span><span class="p">(</span><span class="s">'maggie'</span><span class="p">,</span> <span class="s">'baby'</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="n">w2v_model</span><span class="o">.</span><span class="n">wv</span><span class="o">.</span><span class="n">similarity</span><span class="p">(</span><span class="s">'bart'</span><span class="p">,</span> <span class="s">'nelson'</span><span class="p">))</span>



<span class="c1">### Visualization
</span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>

<span class="n">sns</span><span class="o">.</span><span class="n">set_style</span><span class="p">(</span><span class="s">"darkgrid"</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>
<span class="kn">from</span> <span class="nn">sklearn.manifold</span> <span class="kn">import</span> <span class="n">TSNE</span>

<span class="k">def</span> <span class="nf">tsnescatterplot</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">word</span><span class="p">,</span> <span class="n">list_names</span><span class="p">):</span>
    <span class="s">""" Plot in seaborn the results from the t-SNE dimensionality reduction algorithm of the vectors of a query word,
    its list of most similar words, and a list of words.
    """</span>
    <span class="n">arrays</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">300</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s">'f'</span><span class="p">)</span>
    <span class="n">word_labels</span> <span class="o">=</span> <span class="p">[</span><span class="n">word</span><span class="p">]</span>
    <span class="n">color_list</span> <span class="o">=</span> <span class="p">[</span><span class="s">'red'</span><span class="p">]</span>

    <span class="c1"># adds the vector of the query word
</span>    <span class="n">arrays</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">arrays</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">wv</span><span class="o">.</span><span class="n">__getitem__</span><span class="p">([</span><span class="n">word</span><span class="p">]),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="c1"># gets list of most similar words
</span>    <span class="n">close_words</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">wv</span><span class="o">.</span><span class="n">most_similar</span><span class="p">([</span><span class="n">word</span><span class="p">])</span>

    <span class="c1"># adds the vector for each of the closest words to the array
</span>    <span class="k">for</span> <span class="n">wrd_score</span> <span class="ow">in</span> <span class="n">close_words</span><span class="p">:</span>
        <span class="n">wrd_vector</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">wv</span><span class="o">.</span><span class="n">__getitem__</span><span class="p">([</span><span class="n">wrd_score</span><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
        <span class="n">word_labels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">wrd_score</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">color_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s">'blue'</span><span class="p">)</span>
        <span class="n">arrays</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">arrays</span><span class="p">,</span> <span class="n">wrd_vector</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="c1"># adds the vector for each of the words from list_names to the array
</span>    <span class="k">for</span> <span class="n">wrd</span> <span class="ow">in</span> <span class="n">list_names</span><span class="p">:</span>
        <span class="n">wrd_vector</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">wv</span><span class="o">.</span><span class="n">__getitem__</span><span class="p">([</span><span class="n">wrd</span><span class="p">])</span>
        <span class="n">word_labels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">wrd</span><span class="p">)</span>
        <span class="n">color_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s">'green'</span><span class="p">)</span>
        <span class="n">arrays</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">arrays</span><span class="p">,</span> <span class="n">wrd_vector</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="c1"># Reduces the dimensionality from 300 to 50 dimensions with PCA
</span>    <span class="n">reduc</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">arrays</span><span class="p">)</span>

    <span class="c1"># Finds t-SNE coordinates for 2 dimensions
</span>    <span class="n">np</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">suppress</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

    <span class="n">Y</span> <span class="o">=</span> <span class="n">TSNE</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">perplexity</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">reduc</span><span class="p">)</span>

    <span class="c1"># Sets everything up to plot
</span>    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s">'x'</span><span class="p">:</span> <span class="p">[</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">Y</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]],</span>
                       <span class="s">'y'</span><span class="p">:</span> <span class="p">[</span><span class="n">y</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">Y</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]],</span>
                       <span class="s">'words'</span><span class="p">:</span> <span class="n">word_labels</span><span class="p">,</span>
                       <span class="s">'color'</span><span class="p">:</span> <span class="n">color_list</span><span class="p">})</span>

    <span class="n">fig</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">set_size_inches</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">9</span><span class="p">)</span>

    <span class="c1"># Basic plot
</span>    <span class="n">p1</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">regplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span>
                     <span class="n">x</span><span class="o">=</span><span class="s">"x"</span><span class="p">,</span>
                     <span class="n">y</span><span class="o">=</span><span class="s">"y"</span><span class="p">,</span>
                     <span class="n">fit_reg</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
                     <span class="n">marker</span><span class="o">=</span><span class="s">"o"</span><span class="p">,</span>
                     <span class="n">scatter_kws</span><span class="o">=</span><span class="p">{</span><span class="s">'s'</span><span class="p">:</span> <span class="mi">40</span><span class="p">,</span>
                                  <span class="s">'facecolors'</span><span class="p">:</span> <span class="n">df</span><span class="p">[</span><span class="s">'color'</span><span class="p">]</span>
                                  <span class="p">}</span>
                     <span class="p">)</span>

    <span class="c1"># Adds annotations one by one with a loop
</span>    <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="n">p1</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">"x"</span><span class="p">][</span><span class="n">line</span><span class="p">],</span>
                <span class="n">df</span><span class="p">[</span><span class="s">'y'</span><span class="p">][</span><span class="n">line</span><span class="p">],</span>
                <span class="s">'  '</span> <span class="o">+</span> <span class="n">df</span><span class="p">[</span><span class="s">"words"</span><span class="p">][</span><span class="n">line</span><span class="p">]</span><span class="o">.</span><span class="n">title</span><span class="p">(),</span>
                <span class="n">horizontalalignment</span><span class="o">=</span><span class="s">'left'</span><span class="p">,</span>
                <span class="n">verticalalignment</span><span class="o">=</span><span class="s">'bottom'</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="s">'medium'</span><span class="p">,</span>
                <span class="n">color</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="s">'color'</span><span class="p">][</span><span class="n">line</span><span class="p">],</span>
                <span class="n">weight</span><span class="o">=</span><span class="s">'normal'</span>
                <span class="p">)</span><span class="o">.</span><span class="n">set_size</span><span class="p">(</span><span class="mi">15</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="n">Y</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="nb">min</span><span class="p">()</span> <span class="o">-</span> <span class="mi">50</span><span class="p">,</span> <span class="n">Y</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="nb">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">50</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="n">Y</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="nb">min</span><span class="p">()</span> <span class="o">-</span> <span class="mi">50</span><span class="p">,</span> <span class="n">Y</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="nb">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">50</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s">'t-SNE visualization for {}'</span><span class="o">.</span><span class="nb">format</span><span class="p">(</span><span class="n">word</span><span class="o">.</span><span class="n">title</span><span class="p">()))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">tsnescatterplot</span><span class="p">(</span><span class="n">w2v_model</span><span class="p">,</span> <span class="s">'maggie'</span><span class="p">,</span> <span class="p">[</span><span class="n">i</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">w2v_model</span><span class="o">.</span><span class="n">wv</span><span class="o">.</span><span class="n">most_similar</span><span class="p">(</span><span class="n">negative</span><span class="o">=</span><span class="p">[</span><span class="s">"maggie"</span><span class="p">])])</span>

</code></pre></div></div>

  </article>
</div>

<div class="related">
  <h2>Other Posts</h2>
  <ul class="related-posts">
    
    <li>
      <h3>
        <a href="/blog/2019/08/13/docker-image-upload/">
          Docker 이미지 만들기 & 배포하기
          <small>13 Aug 2019</small>
        </a>
      </h3>
    </li>
    
    <li>
      <h3>
        <a href="/bigdata/2019/05/30/textmining-analysis/">
          텍스트 마이닝 프로젝트 : 중고거래 분석 (중고나라)
          <small>30 May 2019</small>
        </a>
      </h3>
    </li>
    
    <li>
      <h3>
        <a href="/bigdata/2019/05/24/real-time-streaming-privacy-preserving/">
          Real-Time Structured Streaming Privacy Preserving
          <small>24 May 2019</small>
        </a>
      </h3>
    </li>
    
  </ul>
</div>


<div class="comments">
  <h2>Comments</h2>
  <div id="disqus_thread"></div>
  <script>
    /*
var disqus_config = function () {
  this.page.url = 'jgtonys.github.io/bigdata/2019/05/16/textmining-word-representation/'; // Replace PAGE_URL with your page's canonical URL variable
  this.page.identifier = '/bigdata/2019/05/16/textmining-word-representation'; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};*/
    (function() {
      var d = document,
        s = d.createElement('script');
      s.src = '//jgtonys.disqus.com/embed.js';
      s.setAttribute('data-timestamp', +new Date());
      (d.head || d.body).appendChild(s);
    })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>
</div>


      </div>
    </div>

    <label for="sidebar-checkbox" class="sidebar-toggle"></label>

    <script>
      (function(document) {
        var toggle = document.querySelector('.sidebar-toggle');
        var sidebar = document.querySelector('#sidebar');
        var checkbox = document.querySelector('#sidebar-checkbox');

        document.addEventListener('click', function(e) {
          var target = e.target;

          if (target === toggle) {
            checkbox.checked = !checkbox.checked;
            e.preventDefault();
          } else if (checkbox.checked && !sidebar.contains(target)) {
            /* click outside the sidebar when sidebar is open */
            checkbox.checked = false;
          }
        }, false);
      })(document);
    </script>
    
    <script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-110053740-1', 'auto');
ga('send', 'pageview');
    </script>
    
  </body>
  
  <script id="dsq-count-scr" src="//jgtonys.disqus.com/count.js" async></script>
  
</html>
