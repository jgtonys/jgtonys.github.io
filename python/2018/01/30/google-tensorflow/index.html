<!DOCTYPE html>
<html lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="naver-site-verification" content="046c0adddf4769b5ef392d86e11c8d31a979c621"/>

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <!-- Twitter Cards -->
	<meta name="twitter:title" content="Tensorflow">
	<meta name="twitter:description" content="Google Tensorflow의 원리를 파악하고
python을 이용한 실습을 해보자

">
	
	
	
	<meta name="twitter:card" content="summary">
	<meta name="twitter:image" content="https://user-images.githubusercontent.com/33674947/56813408-d1b1d400-6877-11e9-9b4f-893fcc6254c6.jpg">
	

	<!-- Open Graph -->
	<meta property="og:locale" content="">
	<meta property="og:type" content="article">
	<meta property="og:title" content="Tensorflow">
	
	<meta name="og:image" content="https://user-images.githubusercontent.com/33674947/56813408-d1b1d400-6877-11e9-9b4f-893fcc6254c6.jpg">
	

	<meta property="og:description" content="Google Tensorflow의 원리를 파악하고
python을 이용한 실습을 해보자

">
	<meta property="og:url" content="http://0.0.0.0:4000/python/2018/01/30/google-tensorflow/">
	<meta property="og:site_name" content="Jungyu Kim">


  <title>
    
      Tensorflow &middot; Jungyu Kim
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/main.css">
  <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Serif:400,400italic,700%7CPT+Sans:400">

  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/public/apple-touch-icon-precomposed.png">
  <link rel="shortcut icon" href="/public/favicon.ico">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">

  <script src="https://code.jquery.com/jquery-3.4.0.min.js" integrity="sha256-BJeo0qm959uMBGb65z40ejJYGSgR7REI4+CW1fNKwOg=" crossorigin="anonymous"></script>

  
  <script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_SVG"> </script>
  <script type="text/x-mathjax-config">
MathJax.Hub.Config({ tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ], processEscapes: true } });
  </script>
  
</head>


  <body>

    <!-- Target for toggling the sidebar `.sidebar-checkbox` is for regular
     styles, `#sidebar-checkbox` for behavior. -->
<input type="checkbox" class="sidebar-checkbox" id="sidebar-checkbox">

<!-- Toggleable sidebar -->
<div class="sidebar" id="sidebar">
  <div class="sidebar-item">
    <div class="sidebar-personal-info">
      <div class="sidebar-personal-info-section">
        <a href="https://github.com/jgtonys">
          <p><strong>Jungyu Kim</strong>
          <i class="fa fa-github" aria-hidden="true"></i></p>
        </a>
        </a>
      </div>
      <div class="sidebar-personal-info-section">
        <p>Wanted to be a <strong>developer</strong><br>And I <strong>am a developer</strong></p>
      </div>
      
      
      
      <div class="sidebar-personal-info-section">
        <p> Contact: 
        
        
        
        <a href="https://github.com/jgtonys">
          <i class="fa fa-github" aria-hidden="true"></i>
        </a>
        
        |
        
        
        
        <a href="https://facebook.com/jgtony">
          <i class="fa fa-facebook" aria-hidden="true"></i>
        </a>
        
        |
        
        
        
        <a href="http://www.google.com/recaptcha/mailhide/d?k=01I3lZFiZYng9N3QxYEtsDaQ==&c=31wAnZkuKqcG0ATAqJN8Z3ln5kkYLA9TwkGc-IbygpM=">
          <i class="fa fa-envelope" aria-hidden="true"></i>
        </a>
        
        |
        
        
        
        <a href="http://www.linkedin.com/in/준규-김-devj">
          <i class="fa fa-linkedin" aria-hidden="true"></i>
        </a>
        
        
        
        </p>
      </div>
      
    </div>
  </div>

  <nav class="sidebar-nav">
    
      
      
      

      

      <span class="">
        <a class="sidebar-nav-item " href="/">
          Home
        </a>

        
      </span>

    
      
      
      

      

      <span class="foldable">
        <a class="sidebar-nav-item " href="/blog/">
          Blog
        </a>

        
          
            
            
            
              <a class="sidebar-nav-item sidebar-nav-item-sub " href="/blog/categories/">
                Categories
              </a>
          
        
          
            
            
            
              <a class="sidebar-nav-item sidebar-nav-item-sub " href="/blog/tags/">
                Tags
              </a>
          
        
      </span>

    
      
      
      

      

      <span class="">
        <a class="sidebar-nav-item " href="/about/">
          About
        </a>

        
      </span>

    
      
      
      

      

      <span class="">
        <a class="sidebar-nav-item " href="http://github.com/jgtonys/">
          Github Project
        </a>

        
      </span>

    

    <!--<span class="sidebar-nav-item">Currently v1.0.0</span>-->
  </nav>

  <div class="sidebar-item">
    <p>
    &copy; 2019 Jungyu Kim.
    </p>
  </div>

  <div class="sidebar-item">
    <p>
    Powered by <a href="http://jekyllrb.com">jekyll</a>
    </p>
  </div>
</div>


    <!-- Wrap is the content to shift when toggling the sidebar. We wrap the
         content to avoid any CSS collisions with our real content. -->
    <div class="wrap">
      <div class="masthead">
        <div class="container">
          <h3 class="masthead-title">
            <a href="/" title="Home" title="Jungyu Kim">
              <!--<img class="masthead-logo" src="/public/logo.jpg"/>-->
              <strong>Jgtony</strong>
            </a>
            <small>Developer blog</small>
          </h3>
        </div>
      </div>

      <div class="container content">
        <div class="post">
  <span class="post-date">30 Jan 2018</span>
  <h1 class="post-title">Tensorflow</h1>
  
  <div class="post-div">
    
    <a href="/blog/tags/#ai" class="post-tag">AI</a>
    
  </div>
  
  <article>
    <script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>
    <p>Google Tensorflow의 원리를 파악하고
python을 이용한 실습을 해보자
<!-- more --></p>

<p><strong>용어</strong></p>

<hr />

<p>-오퍼레이션(Operation)</p>

<p>그래프 상의 노드는 오퍼레이션(줄임말 op)으로 불립니다. 오퍼레이션은 하나 이상의 텐서를 받을 수 있습니다. 오퍼레이션은 계산을 수행하고, 결과를 하나 이상의 텐서로 반환할 수 있습니다.</p>

<p>-텐서(Tensor)</p>

<p>내부적으로 모든 데이터는 텐서를 통해 표현됩니다. 텐서는 일종의 다차원 배열인데, 그래프 내의 오퍼레이션 간에는 텐서만이 전달됩니다. (Caffe의 Blob과 유사합니다.)</p>

<p>-세션(Session)</p>

<p>그래프를 실행하기 위해서는 세션 객체가 필요합니다. 세션은 오퍼레이션의 실행 환경을 캡슐화한 것입니다.</p>

<p>-변수(Variables)</p>

<p>변수는 그래프의 실행시, 패러미터를 저장하고 갱신하는데 사용됩니다. 메모리 상에서 텐서를 저장하는 버퍼 역할을 합니다.</p>

<p>Tensorflow 프로그램은 computational graph 이다. 일련의 Tensorflow Operation을 노드들의 그래프로 구조화(시각화)한 것이다. 노드는 텐서를 입력으로 받아서 텐서를 출력한다.</p>

<p><strong>노드의 종류</strong></p>

<hr />

<ul>
  <li>constant 노드 : 변하지 않는 상수를 저장하는 노드이다.
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span><span class="n">node1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mf">3.0</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span><span class="n">node2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mf">4.0</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span><span class="k">print</span><span class="p">(</span><span class="n">node1</span><span class="p">,</span> <span class="n">node2</span><span class="p">)</span>
<span class="p">(</span><span class="o">&lt;</span><span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span> <span class="s">'Const:0'</span> <span class="n">shape</span><span class="o">=</span><span class="p">()</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="o">&gt;</span><span class="p">,</span> <span class="o">&lt;</span><span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span> <span class="s">'Const_1:0'</span> <span class="n">shape</span><span class="o">=</span><span class="p">()</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="o">&gt;</span><span class="p">)</span>
<span class="c1">#노드가 실제 값을 가지려면 일련의 오퍼레이션을 노드들의 그래프로 구조화하여야 한다. 구조화(평가)하려면 세션(session)을 생성해 주면 된다.
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">sess</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="k">print</span><span class="p">(</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">node1</span><span class="p">,</span> <span class="n">node2</span><span class="p">]))</span>
<span class="p">[</span><span class="mf">3.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">]</span>
</code></pre></div>    </div>
  </li>
  <li>operation 노드 : 노드들의 연산이 저장되는 노드이다.
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">node3</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">node1</span><span class="p">,</span> <span class="n">node2</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="k">print</span><span class="p">(</span><span class="s">"node3: "</span><span class="p">,</span> <span class="n">node3</span><span class="p">)</span>
<span class="p">(</span><span class="s">'node3: '</span><span class="p">,</span> <span class="o">&lt;</span><span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span> <span class="s">'Add:0'</span> <span class="n">shape</span><span class="o">=</span><span class="p">()</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="o">&gt;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="k">print</span><span class="p">(</span><span class="s">"sess.run(node3): "</span><span class="p">,</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">node3</span><span class="p">))</span>
<span class="p">(</span><span class="s">'sess.run(node3): '</span><span class="p">,</span> <span class="mf">7.0</span><span class="p">)</span>
</code></pre></div>    </div>
  </li>
  <li>placeholder 노드 : 외부에서 입력 받을 수 있는 값을 저장하는 노드
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">adder_node</span> <span class="o">=</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span>  <span class="c1"># + provides a shortcut for tf.add(a, b)
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="p">(</span><span class="o">&lt;</span><span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span> <span class="s">'Placeholder:0'</span> <span class="n">shape</span><span class="o">=&lt;</span><span class="n">unknown</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="o">&gt;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">b</span>
<span class="p">(</span><span class="o">&lt;</span><span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span> <span class="s">'Placeholder_1:0'</span> <span class="n">shape</span><span class="o">=&lt;</span><span class="n">unknown</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="o">&gt;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">adder_node</span>
<span class="p">(</span><span class="o">&lt;</span><span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span> <span class="s">'add:0'</span> <span class="n">shape</span><span class="o">=&lt;</span><span class="n">unknown</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="o">&gt;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="k">print</span><span class="p">(</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">adder_node</span><span class="p">,</span> <span class="p">{</span><span class="n">a</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span><span class="mf">4.5</span><span class="p">}))</span>
<span class="mf">7.5</span>
<span class="o">&gt;&gt;&gt;</span> <span class="k">print</span><span class="p">(</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">adder_node</span><span class="p">,</span> <span class="p">{</span><span class="n">a</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">],</span> <span class="n">b</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">]}))</span>
<span class="p">[</span> <span class="mf">3.</span>  <span class="mf">7.</span><span class="p">]</span>
</code></pre></div>    </div>
  </li>
</ul>

<p><strong>실습</strong></p>

<hr />

<p><strong>&lt;선형 방정식 W*x + b 의 computational graph 를 만들어 보자.&gt;</strong></p>

<p>x는 입력되어야 하는 변수이므로 placeholder 노드를 사용한다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</code></pre></div></div>
<p>가중치 W와 바이어스 b는 placeholder와는 달리, 입력 텐서와 출력텐서가 다르다. 훈련을 통해 파라미터(가중치, 바이어스)는 학습해야 하며, 이 경우 Variable을 이용한다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">W</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">([</span><span class="mf">.3</span><span class="p">],</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">([</span><span class="o">-</span><span class="mf">.3</span><span class="p">],</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">linear_model</span> <span class="o">=</span> <span class="n">W</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="n">b</span>
</code></pre></div></div>

<p>변수는 초기화해서 사용해야 하며, tf.global_variables_initializer()를 이용한다.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">init</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">init</span><span class="p">)</span>
</code></pre></div></div>
<p>초기화된 변수 W와 b의 출력은 다음과 같다.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="k">print</span><span class="p">(</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">W</span><span class="p">))</span>
<span class="p">[</span> <span class="mf">0.30000001</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="k">print</span><span class="p">(</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">b</span><span class="p">))</span>
<span class="p">[</span><span class="o">-</span><span class="mf">0.30000001</span><span class="p">]</span>
</code></pre></div></div>

<p>이제 입력 x = [1,2,3,4]를 이용하여 선형 방정식을 평가해 보자.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="k">print</span><span class="p">(</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">linear_model</span><span class="p">,</span> <span class="p">{</span><span class="n">x</span><span class="p">:[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">]}))</span>
<span class="p">[</span> <span class="mf">0.</span>          <span class="mf">0.30000001</span>  <span class="mf">0.60000002</span>  <span class="mf">0.90000004</span><span class="p">]</span>
</code></pre></div></div>
<p><br /><br />
**<모델의 정확도="" 판별="">**</모델의></p>

<p>모델의 예측값과 실제 결과값 사이의 차이를 평가한다. 이때 여기에서는 squared error 함수를 손실 함수로 사용하여 실습하겠다.</p>

<p>실제 결과값 y</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</code></pre></div></div>
<p>손실함수(squared error) : 실제 결과값과 예측값의 차이를 제곱하여 모든 테스트마다 더한다. (Y1-y1)^2 + (Y2-y2)^2 + …</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">squared_deltas</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">linear_model</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">squared_deltas</span><span class="p">)</span>
</code></pre></div></div>

<p>실제 y=[0, -1, -2, -3] 값을 이용하여 손실을 평가한다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="k">print</span><span class="p">(</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="p">{</span><span class="n">x</span><span class="p">:[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">],</span> <span class="n">y</span><span class="p">:[</span><span class="mi">0</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="o">-</span><span class="mi">3</span><span class="p">]}))</span>
<span class="mf">23.66</span>
</code></pre></div></div>
<p>loss 계산은 다음과 같다.
(0. ? 0.)^2 + (0.3 ? (-1))^2 + (0.6 ? (-2))^2 + (0.9 ? (-3))^2
= 0 + 1.69 + 6.76 + 15.2
= 23.66</p>

<p>실제 모델의 학습하려는 값은 W=1, b=-1 이다.
이를 넣어서 계산하여 보면</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">fixW</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mf">1.</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">fixb</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="p">[</span><span class="mf">1.</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">fixW</span><span class="p">,</span> <span class="n">fixb</span><span class="p">])</span>
<span class="p">[</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mf">1.</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">),</span> <span class="n">array</span><span class="p">([</span> <span class="mf">1.</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">)]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="k">print</span><span class="p">(</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="p">{</span><span class="n">x</span><span class="p">:[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">],</span> <span class="n">y</span><span class="p">:[</span><span class="mi">0</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="o">-</span><span class="mi">3</span><span class="p">]}))</span>
<span class="mf">0.0</span>
</code></pre></div></div>

<p>손실은 0이 된다. 즉 정확한 예측이 된다.</p>

<p><br /><br />
<strong>&lt;학습(tf.train API)&gt;</strong></p>

<p>실제 예측값으로 수렴하기 위해 프로그램을 계속 학습시켜야 한다.</p>

<p>W와 b가 진짜 값인 -1,1에 수렴하도록 학습시키는 것이다.</p>

<p>최적화 함수로 gradient descent를 사용한다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">GradientDescentOptimizer</span><span class="p">(</span><span class="mf">0.01</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">train</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
</code></pre></div></div>

<p>그리고 파라미터를 다시 랜덤값으로 초기화한 후, 반복 훈련시킨다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">init</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">):</span>
<span class="o">...</span>  <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="p">{</span><span class="n">x</span><span class="p">:[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">],</span> <span class="n">y</span><span class="p">:[</span><span class="mi">0</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="o">-</span><span class="mi">3</span><span class="p">]})</span>
</code></pre></div></div>

<p>학습된 파라미터를 출력해 본다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="k">print</span><span class="p">(</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">W</span><span class="p">,</span> <span class="n">b</span><span class="p">]))</span>
<span class="p">[</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mf">0.9999969</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">),</span> <span class="n">array</span><span class="p">([</span> <span class="mf">0.99999082</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">)]</span>
</code></pre></div></div>

<p>W와 b가 각각 -1과 1에 근접했음을 확인할 수 있다. 현재까지 훈련된 파라미터와 손실을 출력해 보자.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">curr_W</span><span class="p">,</span> <span class="n">curr_b</span><span class="p">,</span> <span class="n">curr_loss</span>  <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">W</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">loss</span><span class="p">],</span> <span class="p">{</span><span class="n">x</span><span class="p">:[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">],</span> <span class="n">y</span><span class="p">:[</span><span class="mi">0</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="o">-</span><span class="mi">3</span><span class="p">]})</span>
<span class="o">&gt;&gt;&gt;</span> <span class="k">print</span><span class="p">(</span><span class="s">"W: </span><span class="si">%</span><span class="s">s b: </span><span class="si">%</span><span class="s">s loss: </span><span class="si">%</span><span class="s">s"</span><span class="o">%</span><span class="p">(</span><span class="n">curr_W</span><span class="p">,</span> <span class="n">curr_b</span><span class="p">,</span> <span class="n">curr_loss</span><span class="p">))</span>
<span class="n">W</span><span class="p">:</span> <span class="p">[</span><span class="o">-</span><span class="mf">0.9999969</span><span class="p">]</span> <span class="n">b</span><span class="p">:</span> <span class="p">[</span> <span class="mf">0.99999082</span><span class="p">]</span> <span class="n">loss</span><span class="p">:</span> <span class="mf">5.69997e-11</span>
</code></pre></div></div>

<p>W와 b의 값이 거의 -1과 1로 수렴하는 것을 볼 수 있다.</p>

<p><br /><br />
<strong>&lt;고수준 학습(tf.contrib.learn)&gt;</strong></p>

<p>텐서플로우에서 제공하는 tf.contrib.learn을 이용하여 앞의 예제를 다시 만들어 보겠다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
 
<span class="c1"># x를 1차원으로 정의한다.
</span><span class="n">features</span> <span class="o">=</span> <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">real_valued_column</span><span class="p">(</span><span class="s">"x"</span><span class="p">,</span> <span class="n">dimension</span><span class="o">=</span><span class="mi">1</span><span class="p">)]</span>
 
<span class="c1"># 훈련모델을 정의하는데, 여기서 훈련 모델은 linear regressor 를 사용한다.
</span><span class="n">estimator</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">learn</span><span class="o">.</span><span class="n">LinearRegressor</span><span class="p">(</span><span class="n">feature_columns</span><span class="o">=</span><span class="n">features</span><span class="p">)</span>
 
<span class="c1"># 훈련 데이터셋과 배치사이즈, 에폭스를 정의한다.
</span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.</span><span class="p">])</span>
<span class="n">input_fn</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">learn</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">numpy_input_fn</span><span class="p">({</span><span class="s">"x"</span><span class="p">:</span><span class="n">x</span><span class="p">},</span> <span class="n">y</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">num_epochs</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
 
<span class="c1"># 모델을 1000번 반복학습시킨다.
</span><span class="n">estimator</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">input_fn</span><span class="o">=</span><span class="n">input_fn</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
 
<span class="c1"># 훈련된 모델을 평가한다.
</span><span class="n">estimator</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">input_fn</span><span class="o">=</span><span class="n">input_fn</span><span class="p">)</span>
</code></pre></div></div>


  </article>
</div>

<div class="related">
  <h2>Other Posts</h2>
  <ul class="related-posts">
    
    <li>
      <h3>
        <a href="/blog/2019/08/13/docker-image-upload/">
          Docker 이미지 만들기 & 배포하기
          <small>13 Aug 2019</small>
        </a>
      </h3>
    </li>
    
    <li>
      <h3>
        <a href="/blog/2019/07/20/jekyll-code-block-liquid-escape/">
          Jekyll Code Block 에서 liquid tag Escape
          <small>20 Jul 2019</small>
        </a>
      </h3>
    </li>
    
    <li>
      <h3>
        <a href="/algorithm/2019/07/18/algorithm(6)/">
          알고리즘 - 브루트 포스(중급)
          <small>18 Jul 2019</small>
        </a>
      </h3>
    </li>
    
  </ul>
</div>


<div class="comments">
  <h2>Comments</h2>
  <div id="disqus_thread"></div>
  <script>
    /*
var disqus_config = function () {
  this.page.url = 'http://0.0.0.0:4000/python/2018/01/30/google-tensorflow/'; // Replace PAGE_URL with your page's canonical URL variable
  this.page.identifier = '/python/2018/01/30/google-tensorflow'; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};*/
    (function() {
      var d = document,
        s = d.createElement('script');
      s.src = '//jgtonys.disqus.com/embed.js';
      s.setAttribute('data-timestamp', +new Date());
      (d.head || d.body).appendChild(s);
    })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>
</div>


      </div>
    </div>

    <label for="sidebar-checkbox" class="sidebar-toggle"></label>

    <script>
      (function(document) {
        var toggle = document.querySelector('.sidebar-toggle');
        var sidebar = document.querySelector('#sidebar');
        var checkbox = document.querySelector('#sidebar-checkbox');

        document.addEventListener('click', function(e) {
          var target = e.target;

          if (target === toggle) {
            checkbox.checked = !checkbox.checked;
            e.preventDefault();
          } else if (checkbox.checked && !sidebar.contains(target)) {
            /* click outside the sidebar when sidebar is open */
            checkbox.checked = false;
          }
        }, false);
      })(document);
    </script>
    
    <script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-110053740-1', 'auto');
ga('send', 'pageview');
    </script>
    
  </body>
  
  <script id="dsq-count-scr" src="//jgtonys.disqus.com/count.js" async></script>
  
</html>
